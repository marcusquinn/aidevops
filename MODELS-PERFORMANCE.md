# Model Performance

Per-repo performance data from pattern-tracker and response-scoring databases.
Auto-generated by `generate-models-md.sh --mode performance` â€” do not edit manually.
Global model catalog is in `MODELS.md`.
Filtered by repo: `aidevops`

**Last updated**: 2026-02-24T04:04:43Z

- **Pattern data points**: 200
- **Scored responses**: 18
- **Scope**: aidevops (repo-specific)
- **Date range**: 2026-02-05 to 2026-02-23

## Performance Leaderboard

Success rates from autonomous task execution (pattern-tracker data):

| Model | Tasks | Successes | Failures | Success Rate | Last Used |
|-------|-------|-----------|----------|--------------|-----------|
| opus | 24 | 16 | 8 | 66% | 2026-02-23 |
| sonnet | 9 | 9 | 0 | 100% | 2026-02-21 |
| pro | 3 | 2 | 1 | 66% | 2026-02-20 |
| haiku | 1 | 0 | 1 | 0% | 2026-02-05 |

### By Task Type

| Task Type | Tasks | Successes | Failures | Success Rate |
|-----------|-------|-----------|----------|--------------|
| feature | 43 | 22 | 21 | 51% |
| bugfix | 8 | 5 | 3 | 62% |
| refactor | 2 | 0 | 2 | 0% |
| docs | 3 | 3 | 0 | 100% |
| testing | 3 | 2 | 1 | 66% |
| security | 1 | 1 | 0 | 100% |
| architecture | 2 | 2 | 0 | 100% |
| research | 1 | 1 | 0 | 100% |
| content | 6 | 6 | 0 | 100% |

## Contest Results

Quality evaluations from model comparison sessions (response-scoring data):

### Quality Scores

Weighted average across all evaluated responses (correctness 30%, completeness 25%, code quality 25%, clarity 20%):

| Model | Responses | Avg Score | Avg Time (s) |
|-------|-----------|-----------|--------------|
| claude-opus-4 | 6 | 4.56/5.0 | 0.0 |
| claude-sonnet-4 | 6 | 4.28/5.0 | 0.0 |
| gemini-2.5-pro | 6 | 4.11/5.0 | 0.0 |

---

*Generated by [aidevops](https://github.com/marcusquinn/aidevops) t1012, t1133*
