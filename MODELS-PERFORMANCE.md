# Model Performance

Per-repo performance data from pattern-tracker and response-scoring databases.
Auto-generated by `generate-models-md.sh --mode performance` â€” do not edit manually.
Global model catalog is in `MODELS.md`.
Filtered by repo: `aidevops`

**Last updated**: 2026-02-25T04:10:34Z

- **Pattern data points**: 219
- **Scored responses**: 18
- **Scope**: aidevops (repo-specific)
- **Date range**: 2026-02-05 to 2026-02-25

## Performance Leaderboard

Success rates from autonomous task execution (pattern-tracker data):

| Model | Tasks | Successes | Failures | Success Rate | Last Used |
|-------|-------|-----------|----------|--------------|-----------|
| opus | 39 | 22 | 17 | 56% | 2026-02-24 |
| sonnet | 11 | 9 | 2 | 81% | 2026-02-25 |
| pro | 3 | 2 | 1 | 66% | 2026-02-20 |
| haiku | 1 | 0 | 1 | 0% | 2026-02-05 |

### By Task Type

| Task Type | Tasks | Successes | Failures | Success Rate |
|-----------|-------|-----------|----------|--------------|
| feature | 44 | 22 | 22 | 50% |
| bugfix | 9 | 5 | 4 | 55% |
| refactor | 2 | 0 | 2 | 0% |
| docs | 3 | 3 | 0 | 100% |
| testing | 18 | 8 | 10 | 44% |
| security | 1 | 1 | 0 | 100% |
| architecture | 2 | 2 | 0 | 100% |
| research | 1 | 1 | 0 | 100% |
| content | 6 | 6 | 0 | 100% |

## Contest Results

Quality evaluations from model comparison sessions (response-scoring data):

### Quality Scores

Weighted average across all evaluated responses (correctness 30%, completeness 25%, code quality 25%, clarity 20%):

| Model | Responses | Avg Score | Avg Time (s) |
|-------|-----------|-----------|--------------|
| claude-opus-4 | 6 | 4.56/5.0 | 0.0 |
| claude-sonnet-4 | 6 | 4.28/5.0 | 0.0 |
| gemini-2.5-pro | 6 | 4.11/5.0 | 0.0 |

---

*Generated by [aidevops](https://github.com/marcusquinn/aidevops) t1012, t1133*
